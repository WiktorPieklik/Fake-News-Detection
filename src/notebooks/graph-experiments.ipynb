{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports & constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os.path import abspath\n",
    "from typing import Tuple, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizerFast, TFDistilBertModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLossesKeras\n",
    "from scipy.stats import ttest_rel\n",
    "from tabulate import tabulate\n",
    "\n",
    "transformer_checkpoint = 'distilbert-base-uncased'\n",
    "dataset_path = Path(abspath('.')).parent.parent / \"raw\" / \"dataset.csv\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_LENGTH = 512\n",
    "EPOCHS = 80\n",
    "GRAPH_DIM = 5\n",
    "\n",
    "SEED = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T09:19:34.810408Z",
     "start_time": "2023-06-15T09:19:31.918480Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path, lineterminator='\\n')\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data imputation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.description = dataset.description.fillna(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data split (train, val, test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values, test_size=.2, random_state=SEED)\n",
    "\n",
    "# test & val\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=.5, random_state=SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Divide data into graph & nlp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def divide_dataset(dataset: np.ndarray) -> Tuple[tf.constant, np.ndarray]:\n",
    "    \"\"\" Return (graph_X, nlp_X) \"\"\"\n",
    "\n",
    "    bool_encoder = LabelEncoder()\n",
    "    graph_X = dataset[:, [1, 2, 3, 4, 8]]\n",
    "    nlp_X = dataset[:, [5, 6, 7]]\n",
    "    graph_X[:, 1] = bool_encoder.fit_transform(graph_X[:, 1])\n",
    "\n",
    "    return tf.constant(graph_X, dtype='int32'), nlp_X\n",
    "\n",
    "def prepare_nlp_ds(nlp_dataset: np.ndarray) -> List[str]:\n",
    "    dataset = []\n",
    "    for row in nlp_dataset:\n",
    "        dataset.append(row[0]+ \" \" + row[2])\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_train, nlp_train = divide_dataset(X_train)\n",
    "graph_val, nlp_val = divide_dataset(X_val)\n",
    "graph_test, nlp_test = divide_dataset(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Batch encode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def batch_encode(tokenizer: DistilBertTokenizerFast, nlp_dataset: np.ndarray):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for i in range(0, len(nlp_dataset), BATCH_SIZE):\n",
    "        batch = prepare_nlp_ds(nlp_dataset[i: i + BATCH_SIZE])\n",
    "        tokens = tokenizer(\n",
    "            batch,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "        )\n",
    "        input_ids.extend(tokens[\"input_ids\"])\n",
    "        attention_mask.extend(tokens[\"attention_mask\"])\n",
    "\n",
    "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_mask)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(transformer_checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_distill_bert() -> TFDistilBertModel:\n",
    "    distilBERT = TFDistilBertModel.from_pretrained(transformer_checkpoint)\n",
    "    for layer in distilBERT.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return distilBERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp_train_ids, nlp_train_attention = batch_encode(tokenizer, nlp_train)\n",
    "nlp_val_ids, nlp_val_attention = batch_encode(tokenizer, nlp_val)\n",
    "nlp_test_ids, nlp_test_attention = batch_encode(tokenizer, nlp_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_embeddings() -> None:\n",
    "    bert = get_distill_bert()\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(((nlp_train_ids, nlp_train_attention), y_train))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices(((nlp_val_ids, nlp_val_attention), y_val))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(((nlp_test_ids, nlp_test_attention), y_test))\n",
    "\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    train_tokens = np.empty((0, 768))\n",
    "    val_tokens = np.empty((0, 768))\n",
    "    test_tokens = np.empty((0, 768))\n",
    "    with tf.device('/GPU:0'):\n",
    "        print(\"Embedding train dataset\")\n",
    "        for (ids, attention), _ in train_ds:\n",
    "            feature = bert([ids, attention])[0]\n",
    "            cls_token = feature[:, 0, :]\n",
    "            train_tokens = np.append(train_tokens, cls_token.numpy(), axis=0)\n",
    "        np.save('train.embd', train_tokens)\n",
    "        print(\"Embedding val dataset\")\n",
    "        for (ids, attention), _ in val_ds:\n",
    "            feature = bert([ids, attention])[0]\n",
    "            cls_token = feature[:, 0, :]\n",
    "            val_tokens = np.append(val_tokens, cls_token.numpy(), axis=0)\n",
    "        np.save('val.embd', val_tokens)\n",
    "        print(\"Embedding test dataset\")\n",
    "        for (ids, attention), _ in test_ds:\n",
    "            feature = bert([ids, attention])[0]\n",
    "            cls_token = feature[:, 0, :]\n",
    "            test_tokens = np.append(test_tokens, cls_token.numpy(), axis=0)\n",
    "        np.save('test.embd', test_tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_embeddings()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(with_grap_meta: bool = False) -> tf.keras.Model:\n",
    "    input_embedding_layer = tf.keras.layers.Input(shape=(768,), name='input_embedding_layer', dtype='float32')\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(input_embedding_layer)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if with_grap_meta:\n",
    "        input_graph_layer = tf.keras.layers.Input(shape=(GRAPH_DIM,), name='input_graph_stats', dtype='float32')\n",
    "        x = tf.keras.layers.concatenate([x, input_graph_layer])\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(.1)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(40)(x)\n",
    "    x = tf.keras.layers.Dropout(.1)(x)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    if with_grap_meta:\n",
    "        model = tf.keras.Model(inputs=[input_embedding_layer, input_graph_layer], outputs=output)\n",
    "    else:\n",
    "        model = tf.keras.Model(inputs=input_embedding_layer, outputs=output)\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_model = build_model(True)\n",
    "graph_model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),  # due to some issues with Apple M1\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")\n",
    "graph_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_embeddings = np.load('train.embd.npy')\n",
    "val_embeddings = np.load('val.embd.npy')\n",
    "test_embeddings = np.load('test.embd.npy')\n",
    "\n",
    "train_embeddings.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_train_ds = tf.data.Dataset.from_tensor_slices(((train_embeddings, graph_train), y_train))\n",
    "graph_val_ds = tf.data.Dataset.from_tensor_slices(((val_embeddings, graph_val), y_val))\n",
    "graph_test_ds = tf.data.Dataset.from_tensor_slices(((test_embeddings, graph_test), y_test))\n",
    "\n",
    "graph_train_ds = graph_train_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "graph_val_ds = graph_val_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, min_delta=.001, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=.2),\n",
    "    PlotLossesKeras()\n",
    "]\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    graph_history = graph_model.fit(\n",
    "        x=graph_train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=graph_val_ds,\n",
    "        callbacks=callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_model.save('best_graph')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    graph_model.evaluate(graph_test_ds.batch(BATCH_SIZE))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp_model = build_model(False)\n",
    "nlp_model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),  # due to some issues with Apple M1\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")\n",
    "nlp_model.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, min_delta=.001, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=.2),\n",
    "    PlotLossesKeras()\n",
    "]\n",
    "nlp_train_ds = tf.data.Dataset.from_tensor_slices((train_embeddings, y_train))\n",
    "nlp_val_ds = tf.data.Dataset.from_tensor_slices((val_embeddings, y_val))\n",
    "nlp_test_ds = tf.data.Dataset.from_tensor_slices((test_embeddings, y_test))\n",
    "\n",
    "nlp_train_ds = nlp_train_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "nlp_val_ds = nlp_val_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    nlp_history = nlp_model.fit(\n",
    "        x=nlp_train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=nlp_val_ds,\n",
    "        callbacks=callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp_model.save('best_nlp')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensorflow dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    nlp_model.evaluate(nlp_test_ds.batch(BATCH_SIZE))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "models = ['distilBERT + none', 'bert none', 'distilBERT + graph', 'bert + graph', 'lstm unidirectional', 'lstm bidirectional', 'lstm bidirectional + dense64', 'lstm bidirectional + graph']\n",
    "scores = np.array([\n",
    "    [0.87052, 0.8498, 0.7115],\n",
    "    [0.8669, 0.8596, 0.6863],\n",
    "    [0.8663, 0.8454, 0.6948],\n",
    "    [0.8474, 0.8495, 0.6771],\n",
    "    [0.8945, 0.84120, 0.8169],\n",
    "    [0.8971, 0.84257, 0.82544],\n",
    "    [0.8894, 0.8250, 0.8202],\n",
    "    [0.89017, 0.8211, 0.82938],\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T09:28:43.896616Z",
     "start_time": "2023-06-15T09:28:43.888471Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def calculate_t_statistics(scores: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    t_statistic = np.zeros((len(models), len(models)))\n",
    "    p_value = np.zeros((len(models), len(models)))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        for j in range(len(models)):\n",
    "            t_statistic[i, j], p_value[i, j] = ttest_rel(scores[i], scores[j])\n",
    "\n",
    "    return t_statistic, p_value\n",
    "\n",
    "def print_statistics(scores: np.ndarray) -> np.ndarray:\n",
    "    alpha = .05\n",
    "    headers = models\n",
    "    column_names = list(map(lambda model: [model], models))\n",
    "    t_statistics, p_value = calculate_t_statistics(scores)\n",
    "    t_statistics_table = np.concatenate((column_names, t_statistics), axis=1)\n",
    "    t_statistics_table = tabulate(t_statistics_table, headers, floatfmt=\".2f\")\n",
    "    p_value_table = np.concatenate((column_names, p_value), axis=1)\n",
    "    p_value_table = tabulate(p_value_table, headers, floatfmt=\".2f\")\n",
    "    print(\"t-statistic:\\n\", t_statistics_table, \"\\n\\np-value\\n\", p_value_table)\n",
    "    advantage = np.zeros((len(models), len(models)))\n",
    "    advantage[t_statistics > 0] = 1\n",
    "    advantage_table = tabulate(np.concatenate((column_names, advantage), axis=1), headers)\n",
    "    print(\"Advantage:\\n\", advantage_table)\n",
    "    significance = np.zeros((len(models), len(models)))\n",
    "    significance[p_value <= alpha] = 1\n",
    "    significance_table = tabulate(np.concatenate((column_names, significance), axis=1), headers)\n",
    "    print(\"Statistical significance (alpha = 0.05):\\n\", significance_table)\n",
    "\n",
    "    return significance\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T09:44:03.404917Z",
     "start_time": "2023-06-15T09:44:03.402416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic:\n",
      "                                 distilBERT + none    bert none    distilBERT + graph    bert + graph    lstm unidirectional    lstm bidirectional    lstm bidirectional + dense64    lstm bidirectional + graph\n",
      "----------------------------  -------------------  -----------  --------------------  --------------  ---------------------  --------------------  ------------------------------  ----------------------------\n",
      "distilBERT + none                          nan            0.62                  2.04            1.92                  -1.19                 -1.23                           -0.87                         -0.84\n",
      "bert none                                   -0.62       nan                     0.32            3.93                  -1.06                 -1.10                           -0.82                         -0.80\n",
      "distilBERT + graph                          -2.04        -0.32                nan               1.45                  -1.29                 -1.32                           -0.99                         -0.95\n",
      "bert + graph                                -1.92        -3.93                 -1.45          nan                     -1.38                 -1.40                           -1.10                         -1.06\n",
      "lstm unidirectional                          1.19         1.06                  1.29            1.38                 nan                    -1.88                            1.06                          0.42\n",
      "lstm bidirectional                           1.23         1.10                  1.32            1.40                   1.88                nan                               2.70                          1.11\n",
      "lstm bidirectional + dense64                 0.87         0.82                  0.99            1.10                  -1.06                 -2.70                          nan                            -0.53\n",
      "lstm bidirectional + graph                   0.84         0.80                  0.95            1.06                  -0.42                 -1.11                            0.53                        nan \n",
      "\n",
      "p-value\n",
      "                                 distilBERT + none    bert none    distilBERT + graph    bert + graph    lstm unidirectional    lstm bidirectional    lstm bidirectional + dense64    lstm bidirectional + graph\n",
      "----------------------------  -------------------  -----------  --------------------  --------------  ---------------------  --------------------  ------------------------------  ----------------------------\n",
      "distilBERT + none                          nan            0.60                  0.18            0.19                   0.36                  0.34                            0.48                          0.49\n",
      "bert none                                    0.60       nan                     0.78            0.06                   0.40                  0.39                            0.50                          0.51\n",
      "distilBERT + graph                           0.18         0.78                nan               0.28                   0.33                  0.32                            0.43                          0.44\n",
      "bert + graph                                 0.19         0.06                  0.28          nan                      0.30                  0.30                            0.39                          0.40\n",
      "lstm unidirectional                          0.36         0.40                  0.33            0.30                 nan                     0.20                            0.40                          0.71\n",
      "lstm bidirectional                           0.34         0.39                  0.32            0.30                   0.20                nan                               0.11                          0.38\n",
      "lstm bidirectional + dense64                 0.48         0.50                  0.43            0.39                   0.40                  0.11                          nan                             0.65\n",
      "lstm bidirectional + graph                   0.49         0.51                  0.44            0.40                   0.71                  0.38                            0.65                        nan\n",
      "Advantage:\n",
      "                                 distilBERT + none    bert none    distilBERT + graph    bert + graph    lstm unidirectional    lstm bidirectional    lstm bidirectional + dense64    lstm bidirectional + graph\n",
      "----------------------------  -------------------  -----------  --------------------  --------------  ---------------------  --------------------  ------------------------------  ----------------------------\n",
      "distilBERT + none                               0            1                     1               1                      0                     0                               0                             0\n",
      "bert none                                       0            0                     1               1                      0                     0                               0                             0\n",
      "distilBERT + graph                              0            0                     0               1                      0                     0                               0                             0\n",
      "bert + graph                                    0            0                     0               0                      0                     0                               0                             0\n",
      "lstm unidirectional                             1            1                     1               1                      0                     0                               1                             1\n",
      "lstm bidirectional                              1            1                     1               1                      1                     0                               1                             1\n",
      "lstm bidirectional + dense64                    1            1                     1               1                      0                     0                               0                             0\n",
      "lstm bidirectional + graph                      1            1                     1               1                      0                     0                               1                             0\n",
      "Statistical significance (alpha = 0.05):\n",
      "                                 distilBERT + none    bert none    distilBERT + graph    bert + graph    lstm unidirectional    lstm bidirectional    lstm bidirectional + dense64    lstm bidirectional + graph\n",
      "----------------------------  -------------------  -----------  --------------------  --------------  ---------------------  --------------------  ------------------------------  ----------------------------\n",
      "distilBERT + none                               0            0                     0               0                      0                     0                               0                             0\n",
      "bert none                                       0            0                     0               0                      0                     0                               0                             0\n",
      "distilBERT + graph                              0            0                     0               0                      0                     0                               0                             0\n",
      "bert + graph                                    0            0                     0               0                      0                     0                               0                             0\n",
      "lstm unidirectional                             0            0                     0               0                      0                     0                               0                             0\n",
      "lstm bidirectional                              0            0                     0               0                      0                     0                               0                             0\n",
      "lstm bidirectional + dense64                    0            0                     0               0                      0                     0                               0                             0\n",
      "lstm bidirectional + graph                      0            0                     0               0                      0                     0                               0                             0\n"
     ]
    }
   ],
   "source": [
    "significance = print_statistics(scores)\n",
    "significance\n",
    "raw_df = {model: significance[:, i] for i, model in enumerate(models)}\n",
    "df = pd.DataFrame(raw_df, index=models, columns=models)\n",
    "df.to_csv('wyniki.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T09:44:08.837878Z",
     "start_time": "2023-06-15T09:44:08.834404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
